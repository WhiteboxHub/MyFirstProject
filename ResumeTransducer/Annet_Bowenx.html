<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta name="cp:revision" content="1" />
<meta name="meta:save-date" content="2016-08-28T13:41:00Z" />
<meta name="Application-Name" content="Microsoft Office Word" />
<meta name="dcterms:created" content="2016-08-28T13:41:00Z" />
<meta name="Application-Version" content="12.0000" />
<meta name="Character-Count-With-Spaces" content="10855" />
<meta name="date" content="2016-08-28T13:41:00Z" />
<meta name="extended-properties:Template" content="Normal" />
<meta name="meta:line-count" content="77" />
<meta name="Word-Count" content="1623" />
<meta name="meta:paragraph-count" content="21" />
<meta name="Creation-Date" content="2016-08-28T13:41:00Z" />
<meta name="extended-properties:AppVersion" content="12.0000" />
<meta name="Line-Count" content="77" />
<meta name="extended-properties:Application" content="Microsoft Office Word" />
<meta name="Paragraph-Count" content="21" />
<meta name="dc:title" content="BigData" />
<meta name="Last-Save-Date" content="2016-08-28T13:41:00Z" />
<meta name="Revision-Number" content="1" />
<meta name="dcterms:modified" content="2016-08-28T13:41:00Z" />
<meta name="meta:creation-date" content="2016-08-28T13:41:00Z" />
<meta name="Template" content="Normal" />
<meta name="Page-Count" content="4" />
<meta name="meta:character-count" content="9253" />
<meta name="Last-Modified" content="2016-08-28T13:41:00Z" />
<meta name="meta:word-count" content="1623" />
<meta name="modified" content="2016-08-28T13:41:00Z" />
<meta name="xmpTPg:NPages" content="4" />
<meta name="Character Count" content="9253" />
<meta name="meta:page-count" content="4" />
<meta name="meta:character-count-with-spaces" content="10855" />
<meta name="Content-Type" content="application/vnd.openxmlformats-officedocument.wordprocessingml.document" />
<title>BigData</title>
</head>
<body><p><b>Anne Bowen</b></p>
<p><b> </b><a href="mailto:annebowen@fairhint.com">annebowen@fairhint.com</a></p>
<p><b>2529660203</b></p>
<p />
<p><b>Summary:</b></p>
<p class="body_Text">Over8years of professional IT experience with 5+ plus years of experience in analysis, architectural design, prototyping, development, Integration and testing of applications using Java/J2EE Technologies and 3+ years of experience in Big Data Analytics as Hadoop Developer with good knowledge in Hadoop ecosystem technologies.</p>
<p class="body_Text">Delivery experience on major Hadoop ecosystem Components such as Pig, Hive, Spark Kafka, Elastic Search &amp;Hbase and monitoring with Cloudera Manager.Extensive working experience using Sqoop to import data into HDFS from RDBMS and vice-versa.</p>
<p class="body_Text">In-depth experience and knowledge in developing and analyzing Map Reduce Jobs and Applications developed standalone and/or through Pig/Hive.</p>
<p class="body_Text">Extensive experience in developing Pig Latin Scripts  for transformations and using Hive Query Language for data analytics.In depth knowledge of Spark concepts and experience with Spark in Data Transformation and Processing.</p>
<p class="body_Text">Hands on experience working on NoSQL databases including Hbase, Cassandra and its integration with Hadoop cluster.Experience in development and utilization of Apache SOLR with Data Computations and Transformation for use by Down Stream Online Applications.</p>
<p class="body_Text">Good experience in ETL tool Informatica.</p>
<p class="body_Text">Solid experience in developing job workflows and schedules with Oozie, and IBM Tivoli</p>
<p>Experience in Hadoop administration activities such as installation and configuration of clusters using Apache, Cloudera and AWS.Working on Automation using Perl, Shell,Python and Scala Scripts.Developed UDFs in Java as and when necessary.</p>
<p>Training and Knowledge in Mahout, Spark MLlib for use in data classification, regression analysis, recommendation engines and anomaly detection.Automating the jobs using Unix shell scripting and providing production support.</p>
<p>Training and Knowledge in Mahout, Spark MLlib for use in data classification, regression analysis, recommendation engines and anomaly detection.</p>
<p>Good experience in Python.Developed UDFs in Java as and when necessary to use in PIG and HIVE queries.</p>
<p>Working knowledge of database such as Oracle 8i/9i/10g, Microsoft SQL Server, DB2, Netezza.</p>
<p>Good experience in Oracle Business Intelligence Enterprise Edition(OBIEE)</p>
<p class="body_Text">Experienced in using Version Control Tools like SubVersion, Git.Experience in development of logging standards and mechanism based on Log4J.Good understanding and experience with Software Development methodologies like Agile and Waterfall.</p>
<p>Experienced in design, development, Unit testing,integration, debugging and implementation and production support, client interaction and understanding business application, business data flow and data relations from them.</p>
<p class="body_Text" />
<p><b>Technical Skills:</b></p>
<table><tbody><tr>	<td><p><b>Hadoop/Big Data Technologies</b></p>
</td>	<td><p>HDFS, MapReduce, Spark, Hive, Pig, Sqoop, Flume, HBase, Cassandra,  Oozie, Zookeeper, YARN, Hue, Ambari, Kafka, Elastic Search, Cloudera, Hortonworks, Tez, Apache Parquet</p>
</td></tr>
<tr>	<td><p><b>Programming Languages</b></p>
</td>	<td><p>Java JDK1.4/1.5/1.6 (JDK 5/JDK 6), C/C++, Unix Shell Scripting, Python</p>
</td></tr>
<tr>	<td><p><b>Web /Applications Servers</b></p>
</td>	<td><p>Apache Tomcat, Weblogic, WebSphere and Bastion.</p>
</td></tr>
<tr>	<td><p><b>Operating Systems</b></p>
</td>	<td><p>UNIX, Windows, LINUX</p>
</td></tr>
<tr>	<td><p><b>Databases</b></p>
</td>	<td><p>HBase, Oracle 8i/9i/10g, Microsoft SQL Server 2008/2012, DB2 &amp; MySQL 4.x/5.x, Teradata, Mongo DB</p>
</td></tr>
<tr>	<td><p><b>Java IDE</b></p>
</td>	<td><p>Eclipse 3.x, IBM Web Sphere Application Developer, IBM RAD 7.0</p>
</td></tr>
<tr>	<td><p><b>Tools</b></p>
</td>	<td><p>TOAD, SQL Developer, SOAP UI, ANT, Maven</p>
</td></tr>
</tbody></table>
<p />
<p><a name="_GoBack" /><b>Professional Experience:</b></p>
<p />
<p><b>American Express,Houston, TX							Oct 14 – Present</b></p>
<p><b>Sr. Big Data/Hadoop Developer</b></p>
<p><b>Responsibilities:</b></p>
<p class="body_Text">Coordinated with business customers to gather business requirements. And also interact with other technical peers to derive Technical requirements and delivered the BRD and TDD documents. </p>
<p class="body_Text">Extensively involved in Design phase and delivered Design documents. Experience in Hadoop eco system with HDFS, HIVE, PIG, SQOOP and SPARK with SCALA.</p>
<p class="body_Text">Worked on analyzing Hadoop cluster and different Big Data Components including Pig, Hive,Spark, HBase, Kafka, Elastic Search, database and SQOOP. Installed Hadoop, Map Reduce, HDFS, and developed multiple Map-Reduce jobs in PIG and Hive for data cleaning and pre-processing. </p>
<p class="body_Text">Importing and exporting data into HDFS and Hive using SQOOP. </p>
<p class="body_Text">Migration of 100+ TBs of data from different databases (i.e. Netezza, Oracle, SQL Server) to Hadoop. </p>
<p class="body_Text">Written Hive jobs to parse the logs and structure them in tabular format to facilitate effective querying on the log data. </p>
<p class="body_Text">Involved in creating Hive tables, loading with data and writing hive queries that will run internally in map reduce way. Generate OBIEE reports to verify the Hive tables data.</p>
<p class="body_Text">Experienced in defining job flows.Used Hive to analyze the partitioned and bucketed data and compute various metrics for reporting. Experienced in managing and reviewing the Hadoop log files.</p>
<p class="body_Text">Used Pig as ETL tool to do Transformations with joins and pre-aggregations before storing the data onto HDFS. Responsible to develop data pipelines from different sources</p>
<p class="body_Text">Utilized Apache Hadoop environment by Cloud era Distribution.Exported data from HDFS environment into RDBMS using Sqoop for report generation and visualization purpose. </p>
<p class="body_Text">Worked on Oozie workflow engine for job scheduling.Involved in Unit testing and delivered Unit test plans and results documents. </p>
<p><b>Environment: </b>Hadoop, MapReduce, HDFS, Hive, Pig, Hue, Ganglia, Nagios, Java, Kafka, Elastic Search, SQL, Scala, Oracle, Netezza, Ambari, Sqoop, Flume, Oozie, Java (jdk 1.6), Eclipse.</p>
<p />
<p><b>Kindred Healthcare,Arlington,TX						Mar  12 – Sep14</b></p>
<p><b>Big Data Tools Expert / Hadoop Developer</b></p>
<p><b>Responsibilities:</b></p>
<p>Hands on experience in loading data from UNIX file system and Teradata to HDFS</p>
<p>Experienced on loading and transforming of large sets of structured, semi structured and unstructured data from HBase through Sqoop and placed in HDFS for further processing.</p>
<p class="body_Text">Installed and configured Flume, Hive, Pig, Sqoop and Oozie on the Hadoop cluster.</p>
<p class="body_Text">Involved in creating Hive tables, loading data and running hive queries in those data.</p>
<p class="body_Text">Extensive Working knowledge of partitioned table, UDFs, performance tuning, compression-related properties, thrift server in Hive.</p>
<p class="body_Text">Involved in writing optimized Pig Script along with involved in developing and testing Pig Latin Scripts</p>
<p class="body_Text">Working knowledge in writing Pig’s Load and Store functions.</p>
<p class="body_Text">Developed Java MapReduce programs on log data to transform into structured way to find user location, age group, spending time. </p>
<p class="body_Text">Developed optimal strategies for distributing the web log data over the cluster, importing and exporting the stored web log data into HDFS and Hive using Scoop. </p>
<p class="body_Text">Collected and aggregated large amounts of web log data from different sources such as webservers, mobile and network devices using Apache Flume and stored the data into HDFS for analysis</p>
<p class="body_Text">Monitored multiple Hadoop clusters environments using Ganglia. </p>
<p class="body_Text">Developed PIG scripts for the analysis of semi structured data. </p>
<p class="body_Text">Developed and involved in the industry specific UDF (user defined functions). </p>
<p class="body_Text">Used Flume to collect, aggregate, and store the web log data from different sources like web servers, mobile and network devices and pushed to HDFS. </p>
<p>Analyzed the web log data using the HiveQL to extract number of unique visitors per day, page views, visit duration, most purchased product on website. </p>
<p class="body_Text">Integrated Oozie with the rest of the Hadoop stack supporting several types of Hadoop jobs out of the box (such as Map-Reduce, Pig, Hive, and Sqoop) as well as system specific jobs (such as Java programs and shell scripts).</p>
<p class="body_Text">Monitored workload, job performance and capacity planning using Cloudera Manager.</p>
<p class="body_Text">Managing and scheduling Jobs on a Hadoop cluster using Oozie.</p>
<p class="body_Text"><b>Environment: </b>Amazon EC2, Apache Hadoop 1.0.1, MapReduce, HDFS, CentOS 6.4,  HBase, Kafka, Scala, Elastic Search, Hive, Pig, Oozie, Flume, Java (jdk 1.6), Eclipse, Sqoop, Ganglia, Hbase.</p>
<p class="list_Paragraph" />
<p><b>Krogers Stores, Marietta,GA						Oct 10 – Feb 12</b></p>
<p class="list_Paragraph"><b>Java Developer</b></p>
<p class="list_Paragraph"><b>Responsibilities:</b></p>
<p>Responsible for requirement gathering and analysis through interaction with end users.</p>
<p>Involved in designing use-case diagrams, class diagram, interaction using UML model with Rational Rose.</p>
<p>Designed and developed the application using various design patterns, such as session facade, business delegate and service locator.Developed UDFs in Java as and when necessary to use in PIG and HIVE queries.</p>
<p>Worked on Maven build tool.Involved in developing JSP pages using Struts custom tags, JQuery and Tiles Framework.</p>
<p>Used JavaScript to perform client side validations and Struts-Validator Framework for server-side validation.Developed Web applications with Rich Internet applications using Java applets, Silverlight, JavaFX.</p>
<p>Involved in creating Database SQL and PL/SQL queries and stored Procedures.Implemented Singleton classes for property loading and static data from DB and Debugged and developed applications using Rational Application Developer (RAD).</p>
<p>Developed a Web service to communicate with the database using SOAP.Developed DAO (data access objects) using Spring Framework 3 and Deployed the components in to WebSphere Application server 7.Actively involved in backend tuning SQL queries/DB script.Worked in writing commands using UNIX, Shell scripting.</p>
<p>Involved in developing other subsystems’ server-side components.Production supporting using IBM clear quest for fixing bugs.</p>
<p>Generated Java wrappers for web services using Apache AXIS</p>
<p class="list_Paragraph"><b>Environment</b>: JBoss, XMLSOAP, RESTful, Java EE 6, IBM WebSphere Application Server 7, Apache-Struts 2.0, EJB 3, Spring 3.2, JSP 2.0, Web Services, JQuery 1.7, Servlet 3.0, Struts-Validator, Struts-Tiles, Tag Libraries, ANT 1.5, JDBC, JMS, Service Bus.</p>
<p />
<p><b>GAP Inc,Montgomery, AL								Mar08 – Sep10</b></p>
<p><b>Java Developer	</b></p>
<p><b>Responsibilities:</b></p>
<p>Involved in Design, Development and Support phases of Software Development Life Cycle (SDLC). Used agile methodology and participated in Scrum meetings.</p>
<p>Developed the application using Spring Framework that leverages Model View Layer (MVC) architecture UML diagrams like use cases, class diagrams, interaction diagrams (sequence and collaboration) and activity diagrams were used. Developed UDFs in Java as and when necessary.</p>
<p>Data from UI layer sent through JMS to Middle layer and from there using MDB message retrieves Messages and will be sent to MQSeries.</p>
<p>Used JSON as response type in REST services.</p>
<p>Used RESTFUL client to interact with the services by providing the RESTFUL URL mapping.</p>
<p>Performed unit testing using JUnit.Developed UDFs in Java as and when necessary to use in PIG and HIVE queries.</p>
<p>Provided direction and support for technical architecture with respect to performance, business continuity and seamless integration/functioning of applications, databases, servers, networks.</p>
<p>Managed, administered and maintain more than 100 Oracle databases.</p>
<p><b>Environment:</b>Java SE 6, Servlets, XML, HTML, JavaScript, JSP, Hibernate, Oracle 11g, SQL Navigator.</p>
<p />
<p />
</body></html>